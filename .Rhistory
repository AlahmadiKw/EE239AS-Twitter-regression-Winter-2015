rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ log(x),mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
abline(g$coef, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2, col = 34)
predict(g, data.frame(x = 3), se=T)$fit
summary(g)
summary(g1)
source("Dropbox/internship/reg_an.R")
source("Dropbox/internship/reg_an.R")
plot(y ~ x,mytable)
g <- lm(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5),mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
# abline(g$coef, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2 + g1$coef[4]
plot(y ~ x,mytable)
g <- lm(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5),mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
# abline(g$coef, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2 + g1$coef[4]
summary(g1)
rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5),mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2 + g1$coef[4]*x^3 + g1$coef[5]*x^4 + g1$coef[6]*x^5, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2, col = 34)
rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5),mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
lines(x,g$coef[1] + g$coef[2]*x + g$coef[3]*x^2 + g$coef[4]*x^3 + g$coef[5]*x^4 + g$coef[6]*x^5, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2, col = 34)
rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ x ,mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
abline(g$coef, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2, col = 34)
# my first R script
# run "source("Dropbox/internship/reg_an.R")"
# plot scatter
# plot(y ~ x,mytable)
# linear regression and plot the line
# g <- lm(y ~ x,mytable)
# abline(g$coef, lty=5)
# correlation between variables
# cor(mytable)
# make s prediction
# x0 = data.frame(x = 15)
# predict(g,x0)
# import data
rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ x ,mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
abline(g$coef, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2, col = 34)
# confidance intervals for paramters beta (tut 1 page 37)
# predict
x0 = data.frame(x = 15)
predict(g,x0)
# confidence interval for interval
p <- predict(g, data.frame(x = 30), se=T)
cv <- qt(0.975, 189)
cbind(p$fit, p$fit-cv*p$se, p$fit+cv*p$se)
# plot confidance intervals for preditcions (tut 1, page 52)
# dev.new()
grid <- seq(1,50,0.1)
p <- predict(g,data.frame(x = grid),se=T)
cv <- qt(0.975, 189)
matplot(grid, cbind(p$fit, p$fit-cv*p$se, p$fit+cv*p$se), lty=c(1,2,2), type="l", xlab="x0 values", ylab="predicted y")
rug(mytable$x)
# diagnostics
#-----------------------------
# residuals
## must have a random distribution
plot(g1$res, ylab="Residuals", main="Index plot of residuals")
abline(0, 0, col = 34)
# leverage
## to determine if an x value is spaced far away than the rest
x <- model.matrix(g1)
lev <- hat(x)
plot(lev,ylab="leverages", main="Index plot of leverages")
abline(h=3*sum(lev)/191)
# outlier test
jack <- rstudent(g1)
plot(jack, ylab="Jacknife Residuals", main="Jacknife Residuals")
# dealing with non contant variance page 83
# Assessing Normality using Q-Q plot
qqnorm(g1$res, ylab="Raw Residuals")
qqline(g1$res)
hist(g1$res,10)
# broken stick regression page 98 IMPORTANT
# Assessing Normality using Q-Q plot
library(datasets)
data <-data(iris)
data
iris
mean(iris$Sepal.Length)
apply(split(iris,iris$Species), mean)
sapply(split(iris,iris$Species), mean)
mapply(split(iris,iris$Species), mean)
?apply
?mapply
mapply(mean,split(iris,iris$Species))
mapply(mean,split(iris$Sepal.Length,iris$Species))
data(mtcars)
with(mtcars, tapply(mpg, cyl, mean))
sapply(mtcars, cyl, mean)
apply(mtcars, 2, mean)
x <- with(mtcars, tapply(mpg, cyl, mean))
x
x[1]
x[1][,2]
x[1]-x[2]
abs(15.1-26.66364)
?mtcars
x <- with(mtcars, tapply(hp, cyl, mean))
x
abs(82.63636-209.21429)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)
209.21429-82.63636
cmean <- function(y){
nc <- ncol(y)
means <- numeric(nc)
for(i in 1:nc){
means[i] <- means(y[,i])
}
means
}
cmean(matrix(1:10,2))
trace()
trace(cmean)
cmean(matrix(1:10,2))
cmean <- function(y){
nc <- ncol(y)
means <- numeric(nc)
for(i in 1:nc){
means[i] <- means(y[,i])
}
return(means)
}
cmean(matrix(1:10,2))
cmean <- function(y){
nc <- ncol(y)
means <- numeric(nc)
for(i in 1:nc){
means[i] <- means(y[,i])
}
return(means)
}
cmean(matrix(1:10,2))
matrix(1:10,2)
debug(cmean)
cmean(matrix(1:10,2))
?debug
cmean <- function(y){
nc <- ncol(y)
means <- numeric(nc)
print(means)   # for debugging
#   for(i in 1:nc){
#     means[i] <- means(y[,i])
#   }
#   return(means)
}
cmean(matrix(1:10,2))
cmean <- function(y){
nc <- ncol(y)
means <- nc
print(means)   # for debugging
#   for(i in 1:nc){
#     means[i] <- means(y[,i])
#   }
#   return(means)
}
cmean(matrix(1:10,2))
matrix(1:10,2)
colMeans(matrix(1:10,2)
)
mat <- matrix(1:10,2)
nc <- ncol(mat)
means <- vector(length=5)
cmean <- function(y){
nc <- ncol(y)
means <- vector(length=5)
print(means)   # for debugging
for(i in 1:nc){
means[i] <- means(y[,i])
}
return(means)
}
cmean(matrix(1:10,2))
means <- vector(length=5)
means
means[3] = 5
means
cmean <- function(y){
nc <- ncol(y)
means <- numeric(nc)
print(means)   # for debugging
for(i in 1:nc){
means[i] <- mean(y[,i])
}
return(means)
}
cmean(matrix(1:10,2))
1100 + c(1,-1)*qt(0.975,df=9-1)*30/sqrt(9)
c(1,-1)*qt(0.975,df=9-1)*30/sqrt(9)
c(1,-1)*qt(0.975,df=9-1)
# my first R script
# run "source("Dropbox/internship/reg_an.R")"
# plot scatter
# plot(y ~ x,mytable)
# linear regression and plot the line
# g <- lm(y ~ x,mytable)
# abline(g$coef, lty=5)
# correlation between variables
# cor(mytable)
# make s prediction
# x0 = data.frame(x = 15)
# predict(g,x0)
# import data
rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ x ,mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
abline(g$coef, col = 27)
lines(x,g1$coef[1] + g1$coef[2]*x + g1$coef[3]*x^2, col = 34)
# my first R script
# run "source("Dropbox/internship/reg_an.R")"
# plot scatter
# plot(y ~ x,mytable)
# linear regression and plot the line
# g <- lm(y ~ x,mytable)
# abline(g$coef, lty=5)
# correlation between variables
# cor(mytable)
# make s prediction
# x0 = data.frame(x = 15)
# predict(g,x0)
# import data
rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ x ,mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
abline(g$coef, col = 27)
points(x, predict(g1), type="l", col=27)
# my first R script
# run "source("Dropbox/internship/reg_an.R")"
# plot scatter
# plot(y ~ x,mytable)
# linear regression and plot the line
# g <- lm(y ~ x,mytable)
# abline(g$coef, lty=5)
# correlation between variables
# cor(mytable)
# make s prediction
# x0 = data.frame(x = 15)
# predict(g,x0)
# import data
rm(list=ls())  # clear everything
mytable <- read.table("Documents/MATLAB/internship/myfile.txt", header = TRUE, sep=",")
# attach(mytable)
x <- mytable$X1
y <- mytable$X.4.2874
plot(y ~ x,mytable)
g <- lm(y ~ x ,mytable)
g1 <- lm(y ~ x + I(x^2),mytable)
abline(g$coef, col = 27)
points(x, predict(g1), type="l", col="red")
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("knitr")
install.packages("rgl")
install.packages(""reshape2"")
install.packages(""reshape2")
install.packages("reshape2")
library(rgb)
library(rgl)
##########################
# Regression Analysis for Tweets
#
# Author: Mohammad Mohammad
# Created on Jul 9 2014
# Last revision:
##########################
rm(list=ls())
# import csv data
dat <- read.table("statistics_#NFL.csv", header=TRUE, sep=',')
# sort by hours (24 hours)
dat <- dat[order(dat$from),]
hours <- dat$hr
# remove unnessesarry columns
dat <- data.frame(twt_count = dat$twt_count, hw = dat$from, flwr_cnt = dat$flwrs_count, ret_cnt = dat$ret_cnt, max_flwrs = dat$max_flwrs, hours = dat$hr)
# assign hr as factors
# dat$hours <- as.factor(dat$hours)
# remove outliers
dat <- dat[ which(dat$flwr_cnt<1e8), ]
dat <- aggregate(. ~ hours,
mean,
data = dat)
# plot scatter
plot(dat$flwr_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over the number of Followers", ylab="twt_count", xlab="flwrs_count",
yaxt="n")
plot(dat$hours, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over 24 hrs", ylab="twt_count", xlab="hours",
yaxt="n")
plot(dat$ret_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over retweet sum", ylab="twt_count", xlab="total_retweets",
yaxt="n")
plot(dat$max_flwrs, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over maximum followers", ylab="twt_count", xlab="max_followers",
yaxt="n")
# create predictor
fit <- lm(twt_count ~ hours + flwr_cnt + ret_cnt + max_flwrs, dat)  # 1st order linear model
summary(fit)
# residual plots
# Good model must have a randomly distributed redisual plot. If there is a pattern
# in the plot, the model must be reconsidered
plot(fit$fit, fit$res, ylab="Residuals", main="residuals against estimated cost")
# create predictor
fit <- lm(twt_count ~ hours + flwr_cnt + ret_cnt + max_flwrs, dat)  # 1st order linear model
summary(fit)
setwd("~/Documents/EE239AS_Twitter_Regression")
##########################
# Regression Analysis for Tweets
#
# Author: Mohammad Mohammad
# Created on Jul 9 2014
# Last revision:
##########################
rm(list=ls())
# import csv data
dat <- read.table("statistics_#NFL.csv", header=TRUE, sep=',')
# sort by hours (24 hours)
dat <- dat[order(dat$from),]
hours <- dat$hr
# remove unnessesarry columns
dat <- data.frame(twt_count = dat$twt_count, hw = dat$from, flwr_cnt = dat$flwrs_count, ret_cnt = dat$ret_cnt, max_flwrs = dat$max_flwrs, hours = dat$hr)
# assign hr as factors
# dat$hours <- as.factor(dat$hours)
# remove outliers
dat <- dat[ which(dat$flwr_cnt<1e8), ]
dat <- aggregate(. ~ hours,
mean,
data = dat)
# plot scatter
plot(dat$flwr_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over the number of Followers", ylab="twt_count", xlab="flwrs_count",
yaxt="n")
plot(dat$hours, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over 24 hrs", ylab="twt_count", xlab="hours",
yaxt="n")
plot(dat$ret_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over retweet sum", ylab="twt_count", xlab="total_retweets",
yaxt="n")
plot(dat$max_flwrs, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over maximum followers", ylab="twt_count", xlab="max_followers",
yaxt="n")
# create predictor
fit <- lm(twt_count ~ hours + flwr_cnt + ret_cnt + max_flwrs, dat)  # 1st order linear model
summary(fit)
# residual plots
# Good model must have a randomly distributed redisual plot. If there is a pattern
# in the plot, the model must be reconsidered
plot(fit$fit, fit$res, ylab="Residuals", main="residuals against estimated cost")
# leverage
x <- model.matrix(fit)
lev <- hat(x)
plot(lev,ylab="leverages", main="Index plots of leverages")
abline(h=2*sum(lev)/n, col="red", lwd=2)
critical <- shortest_dis[lev>2*sum(lev)/n]
criticaldata <- data[data$SHRT_DIST_FEET>=min(critical),]
points(critical, criticaldata$EST_COST, col="red", lwd =4 )
# leverage
n <- nrow(dat)
x <- model.matrix(fit)
lev <- hat(x)
plot(lev,ylab="leverages", main="Index plots of leverages")
abline(h=2*sum(lev)/n, col="red", lwd=2)
critical <- shortest_dis[lev>2*sum(lev)/n]
criticaldata <- data[data$SHRT_DIST_FEET>=min(critical),]
points(critical, criticaldata$EST_COST, col="red", lwd =4 )
# leverage
# outlier test and normality
jack <- rstudent(fit)
plot(jack, ylab="Jacknife Residuals", main="Jacknife Residuals")
# influential obseration test
cook <- cooks.distance(fit1)
plot(cook,ylab="Coocs distance")
influen <- match(cook[cook>1],cook)
influenctial_data <- data[influen,]
# influential obseration test
cook <- cooks.distance(fit)
plot(cook,ylab="Coocs distance")
influen <- match(cook[cook>1],cook)
influenctial_data <- data[influen,]
# influential obseration test
cook <- cooks.distance(fit)
plot(cook,ylab="Coocs distance")
influen <- match(cook[cook>1],cook)
influenctial_data <- dat[influen,]
# assesing normality and outliers as well
qqnorm(fit$res, ylab="Raw Residuals")
qqline(fit$res)
hist(fit1$res,10)
# assesing normality and outliers as well
qqnorm(fit$res, ylab="Raw Residuals")
qqline(fit$res)
hist(fit$res,10)
summary(fit)
##########################
# Regression Analysis for Tweets
#
# Author: Mohammad Mohammad
# Created on Jul 9 2014
# Last revision:
##########################
rm(list=ls())
# import csv data
dat <- read.table("statistics_#NFL.csv", header=TRUE, sep=',')
# sort by hours (24 hours)
dat <- dat[order(dat$from),]
hours <- dat$hr
# remove unnessesarry columns
dat <- data.frame(twt_count = dat$twt_count, hw = dat$from, flwr_cnt = dat$flwrs_count, ret_cnt = dat$ret_cnt, max_flwrs = dat$max_flwrs, hours = dat$hr)
# assign hr as factors
# dat$hours <- as.factor(dat$hours)
# remove outliers
dat <- dat[ which(dat$flwr_cnt<1e8), ]
dat <- aggregate(. ~ hours,
mean,
data = dat)
# plot scatter
plot(dat$flwr_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over the number of Followers", ylab="twt_count", xlab="flwrs_count",
yaxt="n")
plot(dat$hours, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over 24 hrs", ylab="twt_count", xlab="hours",
yaxt="n")
plot(dat$ret_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over retweet sum", ylab="twt_count", xlab="total_retweets",
yaxt="n")
plot(dat$max_flwrs, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over maximum followers", ylab="twt_count", xlab="max_followers",
yaxt="n")
##########################
# Regression Analysis for Tweets
#
# Author: Mohammad Mohammad
# Created on Jul 9 2014
# Last revision:
##########################
rm(list=ls())
# import csv data
dat <- read.table("statistics_#NFL.csv", header=TRUE, sep=',')
# sort by hours (24 hours)
dat <- dat[order(dat$from),]
hours <- dat$hr
# remove unnessesarry columns
dat <- data.frame(twt_count = dat$twt_count, hw = dat$from, flwr_cnt = dat$flwrs_count, ret_cnt = dat$ret_cnt, max_flwrs = dat$max_flwrs, hours = dat$hr)
# assign hr as factors
# dat$hours <- as.factor(dat$hours)
# remove outliers
# dat <- dat[ which(dat$flwr_cnt<1e8), ]
dat <- aggregate(. ~ hours,
mean,
data = dat)
# plot scatter
plot(dat$flwr_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over the number of Followers", ylab="twt_count", xlab="flwrs_count",
yaxt="n")
plot(dat$hours, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over 24 hrs", ylab="twt_count", xlab="hours",
yaxt="n")
plot(dat$ret_cnt, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over retweet sum", ylab="twt_count", xlab="total_retweets",
yaxt="n")
plot(dat$max_flwrs, dat$twt_count, type="p", lwd=1, col="black", pch=20,
main="Tweet Count over maximum followers", ylab="twt_count", xlab="max_followers",
yaxt="n")
